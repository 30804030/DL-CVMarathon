{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\a0923\\Anaconda3\\envs\\tensorflow114python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\a0923\\Anaconda3\\envs\\tensorflow114python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\a0923\\Anaconda3\\envs\\tensorflow114python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\a0923\\Anaconda3\\envs\\tensorflow114python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\a0923\\Anaconda3\\envs\\tensorflow114python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\a0923\\Anaconda3\\envs\\tensorflow114python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\a0923\\Anaconda3\\envs\\tensorflow114python36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\a0923\\Anaconda3\\envs\\tensorflow114python36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\a0923\\Anaconda3\\envs\\tensorflow114python36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\a0923\\Anaconda3\\envs\\tensorflow114python36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\a0923\\Anaconda3\\envs\\tensorflow114python36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\a0923\\Anaconda3\\envs\\tensorflow114python36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "WARNING:tensorflow:From C:\\Users\\a0923\\Anaconda3\\envs\\tensorflow114python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\a0923\\Anaconda3\\envs\\tensorflow114python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\a0923\\Anaconda3\\envs\\tensorflow114python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\a0923\\Anaconda3\\envs\\tensorflow114python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\a0923\\Anaconda3\\envs\\tensorflow114python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\a0923\\Anaconda3\\envs\\tensorflow114python36\\lib\\site-packages\\ipykernel_launcher.py:41: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(32, 32, 3..., activation=\"relu\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\a0923\\Anaconda3\\envs\\tensorflow114python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\a0923\\Anaconda3\\envs\\tensorflow114python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\a0923\\Anaconda3\\envs\\tensorflow114python36\\lib\\site-packages\\ipykernel_launcher.py:46: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\")`\n",
      "C:\\Users\\a0923\\Anaconda3\\envs\\tensorflow114python36\\lib\\site-packages\\ipykernel_launcher.py:54: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", kernel_regularizer=<keras.reg..., units=100)`\n",
      "C:\\Users\\a0923\\Anaconda3\\envs\\tensorflow114python36\\lib\\site-packages\\ipykernel_launcher.py:56: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.5)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\a0923\\Anaconda3\\envs\\tensorflow114python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\a0923\\Anaconda3\\envs\\tensorflow114python36\\lib\\site-packages\\keras\\optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\a0923\\Anaconda3\\envs\\tensorflow114python36\\lib\\site-packages\\ipykernel_launcher.py:58: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", kernel_regularizer=<keras.reg..., units=100)`\n",
      "C:\\Users\\a0923\\Anaconda3\\envs\\tensorflow114python36\\lib\\site-packages\\ipykernel_launcher.py:61: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.3)`\n",
      "C:\\Users\\a0923\\Anaconda3\\envs\\tensorflow114python36\\lib\\site-packages\\ipykernel_launcher.py:63: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=10)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\a0923\\Anaconda3\\envs\\tensorflow114python36\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 1/100\n",
      "500/500 [==============================] - 23s 47ms/step - loss: 2.1090 - acc: 0.3521 - val_loss: 1.6198 - val_acc: 0.5008\n",
      "Epoch 2/100\n",
      " 13/500 [..............................] - ETA: 6s - loss: 1.8291 - acc: 0.4208"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\a0923\\Anaconda3\\envs\\tensorflow114python36\\lib\\site-packages\\keras\\callbacks.py:842: RuntimeWarning: Early stopping conditioned on metric `test_loss` which is not available. Available metrics are: val_loss,val_acc,loss,acc\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 20s 39ms/step - loss: 1.6628 - acc: 0.4827 - val_loss: 1.4607 - val_acc: 0.5463\n",
      "Epoch 3/100\n",
      "500/500 [==============================] - 20s 41ms/step - loss: 1.4814 - acc: 0.5354 - val_loss: 1.3658 - val_acc: 0.5713\n",
      "Epoch 4/100\n",
      "500/500 [==============================] - 20s 40ms/step - loss: 1.3727 - acc: 0.5679 - val_loss: 1.1994 - val_acc: 0.6237\n",
      "Epoch 5/100\n",
      "500/500 [==============================] - 20s 40ms/step - loss: 1.3004 - acc: 0.5903 - val_loss: 1.2112 - val_acc: 0.6183\n",
      "Epoch 6/100\n",
      "500/500 [==============================] - 20s 41ms/step - loss: 1.2568 - acc: 0.6031 - val_loss: 1.1802 - val_acc: 0.6257\n",
      "Epoch 7/100\n",
      "500/500 [==============================] - 20s 40ms/step - loss: 1.2248 - acc: 0.6108 - val_loss: 1.1159 - val_acc: 0.6512\n",
      "Epoch 8/100\n",
      "500/500 [==============================] - 20s 39ms/step - loss: 1.2041 - acc: 0.6198 - val_loss: 1.0635 - val_acc: 0.6697\n",
      "Epoch 9/100\n",
      "500/500 [==============================] - 20s 41ms/step - loss: 1.1818 - acc: 0.6299 - val_loss: 1.1749 - val_acc: 0.6342\n",
      "Epoch 10/100\n",
      "500/500 [==============================] - 20s 40ms/step - loss: 1.1655 - acc: 0.6370 - val_loss: 1.1172 - val_acc: 0.6512\n",
      "Epoch 11/100\n",
      "500/500 [==============================] - 20s 39ms/step - loss: 1.1479 - acc: 0.6446 - val_loss: 1.1588 - val_acc: 0.6467\n",
      "Epoch 12/100\n",
      "500/500 [==============================] - 20s 41ms/step - loss: 1.1355 - acc: 0.6470 - val_loss: 1.1076 - val_acc: 0.6566\n",
      "Epoch 13/100\n",
      "500/500 [==============================] - 20s 40ms/step - loss: 1.1308 - acc: 0.6494 - val_loss: 1.1206 - val_acc: 0.6589\n",
      "Epoch 14/100\n",
      "500/500 [==============================] - 20s 39ms/step - loss: 1.1231 - acc: 0.6523 - val_loss: 1.0155 - val_acc: 0.6881\n",
      "Epoch 15/100\n",
      "500/500 [==============================] - 20s 41ms/step - loss: 1.1123 - acc: 0.6571 - val_loss: 1.0201 - val_acc: 0.6890\n",
      "Epoch 16/100\n",
      "500/500 [==============================] - 20s 40ms/step - loss: 1.1011 - acc: 0.6610 - val_loss: 1.1075 - val_acc: 0.6692\n",
      "Epoch 17/100\n",
      "500/500 [==============================] - 20s 39ms/step - loss: 1.0972 - acc: 0.6611 - val_loss: 1.0419 - val_acc: 0.6780\n",
      "Epoch 18/100\n",
      "500/500 [==============================] - 20s 41ms/step - loss: 1.0972 - acc: 0.6627 - val_loss: 0.9841 - val_acc: 0.6998\n",
      "Epoch 19/100\n",
      "500/500 [==============================] - 20s 40ms/step - loss: 1.0818 - acc: 0.6665 - val_loss: 1.0879 - val_acc: 0.6669\n",
      "Epoch 20/100\n",
      "500/500 [==============================] - 20s 39ms/step - loss: 1.0761 - acc: 0.6713 - val_loss: 1.1686 - val_acc: 0.6531\n",
      "Epoch 21/100\n",
      "500/500 [==============================] - 21s 41ms/step - loss: 1.0732 - acc: 0.6725 - val_loss: 0.9946 - val_acc: 0.6977\n",
      "Epoch 22/100\n",
      "500/500 [==============================] - 20s 40ms/step - loss: 1.0718 - acc: 0.6716 - val_loss: 1.0022 - val_acc: 0.6952\n",
      "Epoch 23/100\n",
      "500/500 [==============================] - 20s 41ms/step - loss: 1.0589 - acc: 0.6806 - val_loss: 0.9556 - val_acc: 0.7076\n",
      "Epoch 24/100\n",
      "500/500 [==============================] - 21s 41ms/step - loss: 1.0557 - acc: 0.6779 - val_loss: 0.9713 - val_acc: 0.7050\n",
      "Epoch 25/100\n",
      "500/500 [==============================] - 20s 41ms/step - loss: 1.0556 - acc: 0.6757 - val_loss: 0.9898 - val_acc: 0.7030\n",
      "Epoch 26/100\n",
      "500/500 [==============================] - 20s 40ms/step - loss: 1.0529 - acc: 0.6784 - val_loss: 0.9473 - val_acc: 0.7119\n",
      "Epoch 27/100\n",
      "500/500 [==============================] - 20s 41ms/step - loss: 1.0568 - acc: 0.6781 - val_loss: 1.0702 - val_acc: 0.6745\n",
      "Epoch 28/100\n",
      "500/500 [==============================] - 20s 40ms/step - loss: 1.0464 - acc: 0.6801 - val_loss: 1.0407 - val_acc: 0.6829\n",
      "Epoch 29/100\n",
      "500/500 [==============================] - 20s 40ms/step - loss: 1.0438 - acc: 0.6826 - val_loss: 0.9636 - val_acc: 0.7100\n",
      "Epoch 30/100\n",
      "500/500 [==============================] - 21s 41ms/step - loss: 1.0414 - acc: 0.6842 - val_loss: 1.0429 - val_acc: 0.6845\n",
      "Epoch 31/100\n",
      "500/500 [==============================] - 20s 40ms/step - loss: 1.0422 - acc: 0.6822 - val_loss: 1.0851 - val_acc: 0.6740\n",
      "Epoch 32/100\n",
      "500/500 [==============================] - 20s 39ms/step - loss: 1.0355 - acc: 0.6868 - val_loss: 0.9947 - val_acc: 0.6988\n",
      "Epoch 33/100\n",
      "500/500 [==============================] - 20s 41ms/step - loss: 1.0339 - acc: 0.6875 - val_loss: 0.9970 - val_acc: 0.7006\n",
      "Epoch 34/100\n",
      "500/500 [==============================] - 20s 40ms/step - loss: 1.0350 - acc: 0.6886 - val_loss: 0.9461 - val_acc: 0.7118\n",
      "Epoch 35/100\n",
      "500/500 [==============================] - 20s 40ms/step - loss: 1.0294 - acc: 0.6905 - val_loss: 0.9006 - val_acc: 0.7304\n",
      "Epoch 36/100\n",
      "500/500 [==============================] - 20s 41ms/step - loss: 1.0276 - acc: 0.6924 - val_loss: 0.9731 - val_acc: 0.7078\n",
      "Epoch 37/100\n",
      "500/500 [==============================] - 20s 40ms/step - loss: 1.0239 - acc: 0.6910 - val_loss: 0.9768 - val_acc: 0.7026\n",
      "Epoch 38/100\n",
      "500/500 [==============================] - 20s 40ms/step - loss: 1.0222 - acc: 0.6902 - val_loss: 0.9718 - val_acc: 0.7086\n",
      "Epoch 39/100\n",
      "500/500 [==============================] - 21s 41ms/step - loss: 1.0188 - acc: 0.6930 - val_loss: 0.9693 - val_acc: 0.7090\n",
      "Epoch 40/100\n",
      "500/500 [==============================] - 20s 40ms/step - loss: 1.0171 - acc: 0.6951 - val_loss: 1.0180 - val_acc: 0.6959\n",
      "Epoch 41/100\n",
      "500/500 [==============================] - 21s 41ms/step - loss: 1.0183 - acc: 0.6944 - val_loss: 1.0576 - val_acc: 0.6862\n",
      "Epoch 42/100\n",
      "500/500 [==============================] - 21s 41ms/step - loss: 1.0118 - acc: 0.6931 - val_loss: 1.1252 - val_acc: 0.6696\n",
      "Epoch 43/100\n",
      "500/500 [==============================] - 21s 42ms/step - loss: 1.0169 - acc: 0.6940 - val_loss: 0.9443 - val_acc: 0.7127\n",
      "Epoch 44/100\n",
      "500/500 [==============================] - 20s 40ms/step - loss: 1.0101 - acc: 0.6969 - val_loss: 1.0637 - val_acc: 0.6882\n",
      "Epoch 45/100\n",
      "500/500 [==============================] - 21s 41ms/step - loss: 1.0086 - acc: 0.6975 - val_loss: 0.9914 - val_acc: 0.7042\n",
      "Epoch 46/100\n",
      "500/500 [==============================] - 20s 40ms/step - loss: 1.0139 - acc: 0.6957 - val_loss: 1.0471 - val_acc: 0.6870\n",
      "Epoch 47/100\n",
      "500/500 [==============================] - 20s 39ms/step - loss: 1.0126 - acc: 0.6954 - val_loss: 0.9028 - val_acc: 0.7311\n",
      "Epoch 48/100\n",
      "500/500 [==============================] - 20s 41ms/step - loss: 1.0046 - acc: 0.6991 - val_loss: 0.9365 - val_acc: 0.7161\n",
      "Epoch 49/100\n",
      "500/500 [==============================] - 20s 39ms/step - loss: 1.0071 - acc: 0.6986 - val_loss: 1.0425 - val_acc: 0.6888\n",
      "Epoch 50/100\n",
      "500/500 [==============================] - 20s 40ms/step - loss: 0.9994 - acc: 0.7000 - val_loss: 0.9579 - val_acc: 0.7188\n",
      "Epoch 51/100\n",
      "500/500 [==============================] - 20s 41ms/step - loss: 0.9948 - acc: 0.7024 - val_loss: 0.9826 - val_acc: 0.7120\n",
      "Epoch 52/100\n",
      "500/500 [==============================] - 20s 40ms/step - loss: 0.9956 - acc: 0.6984 - val_loss: 1.0299 - val_acc: 0.6926\n",
      "Epoch 53/100\n",
      "500/500 [==============================] - 20s 40ms/step - loss: 0.9967 - acc: 0.7021 - val_loss: 0.9901 - val_acc: 0.7083\n",
      "Epoch 54/100\n",
      "500/500 [==============================] - 20s 41ms/step - loss: 0.9945 - acc: 0.7015 - val_loss: 0.9688 - val_acc: 0.7123\n",
      "Epoch 55/100\n",
      "500/500 [==============================] - 20s 40ms/step - loss: 0.9925 - acc: 0.7010 - val_loss: 0.9325 - val_acc: 0.7199\n",
      "Epoch 56/100\n",
      "500/500 [==============================] - 20s 40ms/step - loss: 0.9868 - acc: 0.7038 - val_loss: 1.0331 - val_acc: 0.6935\n",
      "Epoch 57/100\n",
      "500/500 [==============================] - 20s 41ms/step - loss: 0.9891 - acc: 0.7032 - val_loss: 1.0387 - val_acc: 0.6901\n",
      "Epoch 58/100\n",
      "500/500 [==============================] - 20s 39ms/step - loss: 0.9865 - acc: 0.7043 - val_loss: 0.9508 - val_acc: 0.7161\n",
      "Epoch 59/100\n",
      "500/500 [==============================] - 20s 40ms/step - loss: 0.9888 - acc: 0.7041 - val_loss: 0.9675 - val_acc: 0.7115\n",
      "Epoch 60/100\n",
      "500/500 [==============================] - 20s 41ms/step - loss: 0.9880 - acc: 0.7046 - val_loss: 0.9414 - val_acc: 0.7191\n",
      "Epoch 61/100\n",
      "500/500 [==============================] - 20s 40ms/step - loss: 0.9875 - acc: 0.7058 - val_loss: 0.9111 - val_acc: 0.7241\n",
      "Epoch 62/100\n",
      "500/500 [==============================] - 20s 40ms/step - loss: 0.9873 - acc: 0.7053 - val_loss: 0.9402 - val_acc: 0.7192\n",
      "Epoch 63/100\n",
      "500/500 [==============================] - 20s 41ms/step - loss: 0.9815 - acc: 0.7064 - val_loss: 1.0072 - val_acc: 0.7011\n",
      "Epoch 64/100\n",
      "500/500 [==============================] - 20s 40ms/step - loss: 0.9797 - acc: 0.7058 - val_loss: 1.0199 - val_acc: 0.7004\n",
      "Epoch 65/100\n",
      "500/500 [==============================] - 20s 40ms/step - loss: 0.9790 - acc: 0.7066 - val_loss: 1.0013 - val_acc: 0.7031\n",
      "Epoch 66/100\n",
      "500/500 [==============================] - 20s 41ms/step - loss: 0.9776 - acc: 0.7048 - val_loss: 0.9362 - val_acc: 0.7165\n",
      "Epoch 67/100\n",
      "500/500 [==============================] - 20s 40ms/step - loss: 0.9890 - acc: 0.7017 - val_loss: 0.9663 - val_acc: 0.7110\n",
      "Epoch 68/100\n",
      "500/500 [==============================] - 20s 40ms/step - loss: 0.9803 - acc: 0.7056 - val_loss: 0.9783 - val_acc: 0.7121\n",
      "Epoch 69/100\n",
      "500/500 [==============================] - 21s 41ms/step - loss: 0.9781 - acc: 0.7066 - val_loss: 0.9365 - val_acc: 0.7211\n",
      "Epoch 70/100\n",
      "500/500 [==============================] - 20s 40ms/step - loss: 0.9756 - acc: 0.7060 - val_loss: 0.8958 - val_acc: 0.7373\n",
      "Epoch 71/100\n",
      "500/500 [==============================] - 20s 40ms/step - loss: 0.9709 - acc: 0.7104 - val_loss: 1.1254 - val_acc: 0.6730\n",
      "Epoch 72/100\n",
      "500/500 [==============================] - 21s 41ms/step - loss: 0.9762 - acc: 0.7078 - val_loss: 0.8902 - val_acc: 0.7349\n",
      "Epoch 73/100\n",
      "500/500 [==============================] - 20s 40ms/step - loss: 0.9768 - acc: 0.7070 - val_loss: 1.0365 - val_acc: 0.6963\n",
      "Epoch 74/100\n",
      "500/500 [==============================] - 19s 39ms/step - loss: 0.9757 - acc: 0.7103 - val_loss: 1.0353 - val_acc: 0.6939\n",
      "Epoch 75/100\n",
      "500/500 [==============================] - 20s 41ms/step - loss: 0.9711 - acc: 0.7118 - val_loss: 0.9942 - val_acc: 0.7088\n",
      "Epoch 76/100\n",
      "500/500 [==============================] - 20s 39ms/step - loss: 0.9677 - acc: 0.7101 - val_loss: 0.9466 - val_acc: 0.7187\n",
      "Epoch 77/100\n",
      "500/500 [==============================] - 20s 40ms/step - loss: 0.9703 - acc: 0.7109 - val_loss: 1.0244 - val_acc: 0.6990\n",
      "Epoch 78/100\n",
      "500/500 [==============================] - 20s 41ms/step - loss: 0.9674 - acc: 0.7111 - val_loss: 1.0262 - val_acc: 0.6955\n",
      "Epoch 79/100\n",
      "500/500 [==============================] - 20s 39ms/step - loss: 0.9678 - acc: 0.7087 - val_loss: 0.9167 - val_acc: 0.7271\n",
      "Epoch 80/100\n",
      "500/500 [==============================] - 20s 39ms/step - loss: 0.9683 - acc: 0.7095 - val_loss: 0.9288 - val_acc: 0.7286\n",
      "Epoch 81/100\n",
      "500/500 [==============================] - 20s 41ms/step - loss: 0.9629 - acc: 0.7125 - val_loss: 1.0408 - val_acc: 0.6948\n",
      "Epoch 82/100\n",
      "500/500 [==============================] - 20s 39ms/step - loss: 0.9676 - acc: 0.7087 - val_loss: 0.9560 - val_acc: 0.7168\n",
      "Epoch 83/100\n",
      "500/500 [==============================] - 19s 39ms/step - loss: 0.9607 - acc: 0.7135 - val_loss: 1.0214 - val_acc: 0.6972\n",
      "Epoch 84/100\n",
      "500/500 [==============================] - 20s 41ms/step - loss: 0.9585 - acc: 0.7152 - val_loss: 0.9070 - val_acc: 0.7342\n",
      "Epoch 85/100\n",
      "500/500 [==============================] - 20s 40ms/step - loss: 0.9671 - acc: 0.7136 - val_loss: 0.9996 - val_acc: 0.7023\n",
      "Epoch 86/100\n",
      "500/500 [==============================] - 19s 39ms/step - loss: 0.9621 - acc: 0.7156 - val_loss: 0.9390 - val_acc: 0.7207\n",
      "Epoch 87/100\n",
      "500/500 [==============================] - 20s 41ms/step - loss: 0.9631 - acc: 0.7110 - val_loss: 0.8497 - val_acc: 0.7502\n",
      "Epoch 88/100\n",
      "500/500 [==============================] - 20s 39ms/step - loss: 0.9683 - acc: 0.7131 - val_loss: 0.9406 - val_acc: 0.7241\n",
      "Epoch 89/100\n",
      "500/500 [==============================] - 19s 39ms/step - loss: 0.9636 - acc: 0.7105 - val_loss: 1.0214 - val_acc: 0.7002\n",
      "Epoch 90/100\n",
      "500/500 [==============================] - 20s 41ms/step - loss: 0.9615 - acc: 0.7128 - val_loss: 0.9423 - val_acc: 0.7211\n",
      "Epoch 91/100\n",
      "500/500 [==============================] - 20s 39ms/step - loss: 0.9599 - acc: 0.7141 - val_loss: 0.9209 - val_acc: 0.7275\n",
      "Epoch 92/100\n",
      "500/500 [==============================] - 20s 39ms/step - loss: 0.9674 - acc: 0.7107 - val_loss: 0.9710 - val_acc: 0.7108\n",
      "Epoch 93/100\n",
      "500/500 [==============================] - 20s 41ms/step - loss: 0.9544 - acc: 0.7155 - val_loss: 0.9701 - val_acc: 0.7085\n",
      "Epoch 94/100\n",
      "500/500 [==============================] - 20s 39ms/step - loss: 0.9629 - acc: 0.7113 - val_loss: 0.9299 - val_acc: 0.7284\n",
      "Epoch 95/100\n",
      "500/500 [==============================] - 19s 39ms/step - loss: 0.9497 - acc: 0.7179 - val_loss: 0.9863 - val_acc: 0.7084\n",
      "Epoch 96/100\n",
      "500/500 [==============================] - 20s 41ms/step - loss: 0.9588 - acc: 0.7138 - val_loss: 0.8865 - val_acc: 0.7428\n",
      "Epoch 97/100\n",
      "500/500 [==============================] - 20s 39ms/step - loss: 0.9614 - acc: 0.7150 - val_loss: 0.8613 - val_acc: 0.7497\n",
      "Epoch 98/100\n",
      "500/500 [==============================] - 20s 39ms/step - loss: 0.9538 - acc: 0.7170 - val_loss: 0.9297 - val_acc: 0.7273\n",
      "Epoch 99/100\n",
      "500/500 [==============================] - 20s 41ms/step - loss: 0.9552 - acc: 0.7151 - val_loss: 0.8928 - val_acc: 0.7384\n",
      "Epoch 100/100\n",
      "500/500 [==============================] - 20s 39ms/step - loss: 0.9526 - acc: 0.7165 - val_loss: 0.9465 - val_acc: 0.7215\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23ed83511d0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.datasets import cifar10\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from keras import regularizers\n",
    "\n",
    "\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "print(x_train.shape) #(50000, 32, 32, 3)\n",
    "\n",
    "## Normalize Data\n",
    "def normalize(X_train,X_test):\n",
    "        mean = np.mean(X_train,axis=(0,1,2,3))\n",
    "        std = np.std(X_train, axis=(0, 1, 2, 3))\n",
    "        X_train = (X_train-mean)/(std+1e-7)\n",
    "        X_test = (X_test-mean)/(std+1e-7)\n",
    "        return X_train, X_test\n",
    "    \n",
    "    \n",
    "## Normalize Training and Testset    \n",
    "x_train, x_test = normalize(x_train, x_test) \n",
    "\n",
    "## OneHot Label 由(None, 1)-(None, 10)\n",
    "one_hot=OneHotEncoder()\n",
    "y_train=one_hot.fit_transform(y_train).toarray()\n",
    "y_test=one_hot.transform(y_test).toarray()\n",
    "\n",
    "\n",
    "classifier=Sequential()\n",
    "\n",
    "#卷積組合\n",
    "classifier.add(Convolution2D(32,3,3,input_shape=(32,32,3),activation='relu'))\n",
    "classifier.add(BatchNormalization())##BatchNormalization\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "#卷積組合\n",
    "classifier.add(Convolution2D(32,3,3,activation='relu'))\n",
    "classifier.add(BatchNormalization())##BatchNormalization\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "#flatten\n",
    "classifier.add(Flatten())\n",
    "\n",
    "#FC\n",
    "classifier.add(Dense(output_dim=100,activation='relu',kernel_regularizer=regularizers.l2(l=0.001))) ##regularizers\n",
    "classifier.add(BatchNormalization()) ##BatchNormalization\n",
    "classifier.add(Dropout(p=0.5)) ##Dropout\n",
    "\n",
    "classifier.add(Dense(output_dim=100,activation='relu',kernel_regularizer=regularizers.l2(0.001)))##regularizers\n",
    "classifier.add(BatchNormalization()) ##BatchNormalization\n",
    "\n",
    "classifier.add(Dropout(p=0.3))##Dropout\n",
    "\n",
    "classifier.add(Dense(output_dim=10,activation='softmax'))\n",
    "#超過兩個就要選categorical_crossentrophy\n",
    "classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator ##Augmentation\n",
    "img_gen = ImageDataGenerator( featurewise_center=True,featurewise_std_normalization=True,rotation_range=10,width_shift_range=0.1,\n",
    "                                            height_shift_range=0.1,shear_range=0.1,zoom_range=0.1,horizontal_flip=True,vertical_flip=False,dtype=np.float32)\n",
    "img_gen.fit(x_train)\n",
    "\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "earlystop = EarlyStopping(monitor='test_loss', patience=8, verbose=1) ##earlystop\n",
    "\n",
    "##開始訓練\n",
    "classifier.fit_generator(img_gen.flow(x_train, y_train, batch_size=100) ,steps_per_epoch=500,\n",
    "                               epochs=100, validation_data = (x_test, y_test),callbacks = [earlystop])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 上方有用到一些避免Overfitting 的方法，有興趣的學員們可以參考這篇Medium:https://medium.com/@CinnamonAITaiwan/cnn%E5%85%A5%E9%96%80-overfitting-d10acd15ec21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 預測新圖片，輸入影像前處理要與訓練時相同\n",
    "#### ((X-mean)/(std+1e-7) ):這裡的mean跟std是訓練集的\n",
    "## 維度如下方示範"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00389634, 0.03561514, 0.27043524, 0.294611  , 0.03410938,\n",
       "        0.24646202, 0.07232887, 0.00360016, 0.00442342, 0.03451842]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_example=(np.zeros(shape=(1,32,32,3))-mean_train)/(std_train+1e-7) \n",
    "classifier.predict(input_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
